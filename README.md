# tdias_dataforge â€“ Scrapy Optimized Crawler ![Python](https://img.shields.io/badge/python-3.11-blue.svg) ![CI/CD](https://github.com/tdiasnet/tdias_dataforge/actions/workflows/ci.yml/badge.svg)

ğŸ” This branch demonstrates a minimalist crawler, built with pure Python using requests, BeautifulSoup, and optional aiohttp. It is designed for low-cost, low-complexity scraping tasks where dependencies must be minimal, and deployment must be fast and lightweight.

    ğŸ§° Perfect for bootstrapping prototypes, testing pipelines, or performing targeted data collection in small-scale applications.

    âš ï¸ This is a portfolio branch. Sensitive data, credentials, and full-scale production logic are intentionally omitted to highlight only the technical structure, modularity, and best practices.
---

## ğŸ“ Project Structure

```plaintext
tdias_dataforge/
â”œâ”€â”€ simple_crawler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ http_crawler.py
â”‚   â””â”€â”€ parser.py
â”œâ”€â”€ data/                 # Raw collected data
â”œâ”€â”€ output/               # Cleaned or processed data
â”œâ”€â”€ .env.example          # Template for environment configuration
â”œâ”€â”€ requirements.txt      # Lightweight dependencies
â”œâ”€â”€ Dockerfile            # Containerization config
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml        # GitHub Actions pipeline
```

âš™ï¸ Core Features

    Built with only essential Python libraries

    Modular separation of crawler logic and parsing

    .env-driven configuration for portability

    Simple output writing to JSON/CSV/local disk

    Fully dockerized and CI/CD-ready

ğŸ§  Why This Matters (For Recruiters)

This branch illustrates:

    ğŸª¶ Lightweight, dependency-minimal scraping workflows

    ğŸ› ï¸ Clean code organization with separation of crawler logic, parsing, and data storage

    âš™ï¸ Infrastructure readiness (Docker + CI/CD) even in small-scale solutions

    ğŸ“ˆ Scalable foundation for more complex systems later

ğŸ›  Technologies Used

    Python 3.11

    Requests + BeautifulSoup (or AIOHTTP)

    Docker

    GitHub Actions

    dotenv config pattern

## ğŸ‘¤ Author

**Thiago Dias Joaquim**  
ğŸ“§ thiago@tdias.net  
ğŸ“ +55 19 99962-0662  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tdiasnet/)

---

ğŸ‘‰ Check other branches for different approaches:

- [`main`](https://github.com/tdiasnet/tdias_dataforge/tree/main) â€“ Complex modular crawler architecture (inspired by Big Tech).
- [`simple_http_crawler`](https://github.com/tdiasnet/tdias_dataforge/tree/simple_http_crawler) â€“ Minimal crawler for simple or resource-limited scenarios.
