# tdias_dataforge â€“ Scrapy Optimized Crawler ![Python](https://img.shields.io/badge/python-3.11-blue.svg) ![CI/CD](https://github.com/tdiasnet/tdias_dataforge/actions/workflows/ci.yml/badge.svg)

ğŸš€ **This branch showcases a Scrapy-based crawler**, optimized for production-level reliability, extensibility, and speed. It is part of the [`tdias_dataforge`](https://github.com/tdiasnet/tdias_dataforge) portfolio project, which demonstrates how modular, scalable crawlers can be built using modern open-source technologies.

> ğŸ”„ **Scrapy** is ideal for structured crawling, automatic request scheduling, throttling, retries, and extensible item pipelines â€” making it a powerful tool for building robust crawlers.

> ğŸ’¡ This is a **portfolio branch**. Sensitive logic, credentials, and full-scale orchestration are intentionally omitted. The goal is to demonstrate architectural design, tool mastery, and code hygiene.

---

## ğŸ“ Project Structure

```plaintext
tdias_dataforge/
â”œâ”€â”€ scrapy_project/
â”‚   â”œâ”€â”€ scrapy.cfg
â”‚   â””â”€â”€ tdias_spider/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ items.py
â”‚       â”œâ”€â”€ middlewares.py
â”‚       â”œâ”€â”€ pipelines.py
â”‚       â”œâ”€â”€ settings.py
â”‚       â””â”€â”€ spiders/
â”‚           â””â”€â”€ example_spider.py
â”œâ”€â”€ data/
â”œâ”€â”€ output/
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml
```


## ğŸ•¸ Features

- Built with Scrapy 2+
- Clean separation of concerns with:
  - Custom item pipeline
  - Middleware for headers/user-agent rotation
  - Configurable output handling
- Follows best practices for Python packaging and version control
- Easily deployable via Docker

## ğŸ”§ Technologies Used

- Python 3.11
- Scrapy Framework
- Docker
- GitHub Actions
- dotenv + modular configuration

## âœ… Why This Matters (For Recruiters)

This crawler demonstrates:

- ğŸ› ï¸ Ability to architect and implement maintainable, scalable web scraping systems
- ğŸš€ CI/CD fluency for automated testing and deployment
- ğŸ§± Code modularity and best practices in real-world applications
- ğŸ“Š Preparation for larger data pipelines (e.g., for NLP or ML training)

## ğŸ‘¤ Author

**Thiago Dias Joaquim**  
ğŸ“§ thiago@tdias.net  
ğŸ“ +55 19 99962-0662  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tdiasnet/)

---

ğŸ‘‰ Check other branches for different approaches:

- [`main`](https://github.com/tdiasnet/tdias_dataforge/tree/main) â€“ Complex modular crawler architecture (inspired by Big Tech).
- [`simple_http_crawler`](https://github.com/tdiasnet/tdias_dataforge/tree/simple_http_crawler) â€“ Minimal crawler for simple or resource-limited scenarios.
